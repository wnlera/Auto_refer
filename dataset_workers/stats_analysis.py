import pandas as pd
df1 = pd.read_csv('../searches/search_stats.csv')
print("search_stats.csv")
print(f"Words count: {df1['key'].count()}")
print(f"Uniq words count: {df1['key'].drop_duplicates().count()}")
df1_uniq = df1.drop_duplicates(subset=['key'])
print(f"Min value: {df1_uniq['found_sentences'].min()}")
print(f"Max value: {df1_uniq['found_sentences'].max()}")
print(f"Mean value: {df1_uniq['found_sentences'].mean()}")
print(f"Zero sentence count: {df1_uniq.loc[df1_uniq['found_sentences'] == 0].count()}")
print(f"Words with zero sentence: {df1_uniq.loc[df1_uniq['found_sentences'] == 0]['key']}")
print("Head of words:")
print(df1_uniq.sort_values(by=['found_sentences'], ascending=False).head(15))
print()
df2 = pd.read_csv('big_files/citation2.csv')
print("citation2.csv")
print(f"Title count: {df2['source_title'].drop_duplicates().count()}")
print(f"Sentence count: {df2['sentence'].drop_duplicates().count()}")
print("==========================================================================")
count_list = df1_uniq['found_sentences'].values.tolist()
result = "\n".join(map(str, count_list))
print(result)
print(count_list)
